# ğŸ” ä¿¡æ¯æœé›†æ¨¡å—

## é€‚ç”¨åœºæ™¯
- æ¸—é€æµ‹è¯•å‰æœŸä¾¦å¯Ÿ
- CTF Web é¢˜ç›®åˆå§‹ä¿¡æ¯æ”¶é›†
- ç›®æ ‡æŠ€æœ¯æ ˆè¯†åˆ«

## æ£€æŸ¥æ¸…å•

```yaml
åŸºç¡€ä¿¡æ¯:
  - [ ] HTTP å“åº”å¤´åˆ†æï¼ˆServer/X-Powered-Byï¼‰
  - [ ] æŠ€æœ¯æ ˆè¯†åˆ«ï¼ˆwhatweb/wappalyzerï¼‰
  - [ ] ç«¯å£æ‰«æï¼ˆnmapï¼‰
  - [ ] å­åŸŸåæšä¸¾
  - [ ] ç›®å½•æ‰«æ

æ•æ„Ÿæ–‡ä»¶:
  - [ ] robots.txt
  - [ ] .git æ³„éœ²
  - [ ] .svn æ³„éœ²
  - [ ] DS_Store æ³„éœ²
  - [ ] å¤‡ä»½æ–‡ä»¶ï¼ˆ.bak/.swp/.zipï¼‰
  - [ ] é…ç½®æ–‡ä»¶ï¼ˆweb.xml/config.phpï¼‰

ä¿¡æ¯æ³„éœ²:
  - [ ] æºç æ³¨é‡Š
  - [ ] JS æ–‡ä»¶åˆ†æ
  - [ ] API æ¥å£å‘ç°
  - [ ] é”™è¯¯ä¿¡æ¯æ³„éœ²
  - [ ] ç‰ˆæœ¬å·æ³„éœ²

å¸¸ç”¨å·¥å…·:
  - nmap, masscan (ç«¯å£æ‰«æ)
  - dirsearch, gobuster, ffuf (ç›®å½•æ‰«æ)
  - whatweb, wappalyzer (æŠ€æœ¯æ ˆè¯†åˆ«)
  - subfinder, amass (å­åŸŸåæšä¸¾)
  - GitHacker, dvcs-ripper (æºç æ³„éœ²)
```

## åˆ†ææµç¨‹

### Step 1: åŸºç¡€ä¿¡æ¯æ”¶é›†

```bash
# HTTP å“åº”å¤´
curl -I http://target.com

# è¯¦ç»†å“åº”ï¼ˆåŒ…å«å“åº”ä½“ï¼‰
curl -v http://target.com

# æŠ€æœ¯æ ˆè¯†åˆ«
whatweb http://target.com
whatweb -v http://target.com  # è¯¦ç»†æ¨¡å¼

# åœ¨çº¿è¯†åˆ«
# https://www.wappalyzer.com/
# https://builtwith.com/
```

### Step 2: ç«¯å£æ‰«æ

```bash
# å¿«é€Ÿæ‰«æå¸¸ç”¨ç«¯å£
nmap -F target.com

# å…¨ç«¯å£æ‰«æ
nmap -p- target.com

# æœåŠ¡è¯†åˆ«
nmap -sV -sC target.com

# æ¼æ´æ‰«æ
nmap --script=vuln target.com

# UDP æ‰«æ
nmap -sU --top-ports 100 target.com

# ç»•è¿‡é˜²ç«å¢™
nmap -Pn -f target.com
nmap -D RND:10 target.com  # è¯±é¥µæ‰«æ
```

### Step 3: ç›®å½•æ‰«æ

```bash
# dirsearchï¼ˆæ¨èï¼‰
dirsearch -u http://target.com -e php,html,txt,bak,zip
dirsearch -u http://target.com -w /path/to/wordlist.txt

# gobuster
gobuster dir -u http://target.com -w /usr/share/wordlists/dirb/common.txt
gobuster dir -u http://target.com -w wordlist.txt -x php,txt,html

# ffufï¼ˆé«˜æ€§èƒ½ï¼‰
ffuf -u http://target.com/FUZZ -w wordlist.txt
ffuf -u http://target.com/FUZZ -w wordlist.txt -e .php,.txt,.html
ffuf -u http://target.com/FUZZ -w wordlist.txt -mc 200,301,302

# feroxbusterï¼ˆé€’å½’æ‰«æï¼‰
feroxbuster -u http://target.com -w wordlist.txt
```

### Step 4: æ•æ„Ÿæ–‡ä»¶æ¢æµ‹

```bash
# robots.txt
curl http://target.com/robots.txt

# .git æ³„éœ²æ£€æµ‹
curl http://target.com/.git/HEAD
curl http://target.com/.git/config
# å¦‚æœå­˜åœ¨ï¼Œä½¿ç”¨ GitHacker æå–
python3 GitHacker.py http://target.com/.git/

# .svn æ³„éœ²
curl http://target.com/.svn/entries
curl http://target.com/.svn/wc.db

# DS_Store æ³„éœ²
curl http://target.com/.DS_Store
# ä½¿ç”¨ ds_store_exp è§£æ
python3 ds_store_exp.py http://target.com/.DS_Store

# å¤‡ä»½æ–‡ä»¶
curl http://target.com/www.zip
curl http://target.com/www.tar.gz
curl http://target.com/backup.sql
curl http://target.com/web.zip
curl http://target.com/1.zip

# vim ä¸´æ—¶æ–‡ä»¶
curl http://target.com/.index.php.swp
curl http://target.com/index.php~
curl http://target.com/index.php.bak

# é…ç½®æ–‡ä»¶
curl http://target.com/web.xml
curl http://target.com/WEB-INF/web.xml
curl http://target.com/config.php.bak
```

### Step 5: å­åŸŸåæšä¸¾

```bash
# subfinder
subfinder -d target.com

# amass
amass enum -d target.com

# åœ¨çº¿å·¥å…·
# https://crt.sh/?q=%.target.com
# https://dnsdumpster.com/

# æš´åŠ›æšä¸¾
gobuster dns -d target.com -w subdomains.txt
wfuzz -c -w subdomains.txt -u http://target.com -H "Host: FUZZ.target.com"
```

### Step 6: JS æ–‡ä»¶åˆ†æ

```bash
# æå–é¡µé¢ä¸­çš„ JS é“¾æ¥
curl http://target.com | grep -oE '(src|href)="[^"]*\.js"'

# ä½¿ç”¨ gau æ”¶é›†æ‰€æœ‰ URL
gau target.com | grep "\.js$"

# ä½¿ç”¨ LinkFinder æå– JS ä¸­çš„ç«¯ç‚¹
python3 linkfinder.py -i http://target.com/app.js -o cli

# ä½¿ç”¨ SecretFinder æŸ¥æ‰¾æ•æ„Ÿä¿¡æ¯
python3 SecretFinder.py -i http://target.com/app.js -o cli

# JS ç¾åŒ–
js-beautify app.js
```

### Step 7: å†å²ä¿¡æ¯æ”¶é›†

```bash
# Wayback Machine
waybackurls target.com | tee urls.txt

# gauï¼ˆå¤šæºèšåˆï¼‰
gau target.com | tee all_urls.txt

# è¿‡æ»¤å‚æ•°åŒ– URL
cat urls.txt | grep "=" | sort -u

# è¿‡æ»¤ç‰¹å®šæ–‡ä»¶ç±»å‹
cat urls.txt | grep -E "\.php|\.asp|\.jsp"
```

## å¸¸è§å‡ºé¢˜å¥—è·¯ä¸è§£æ³•

### å¥—è·¯ 1: .git æºç æ³„éœ²

**ç‰¹å¾**: è®¿é—® `/.git/HEAD` è¿”å› `ref: refs/heads/master`

**è§£æ³•**:
```bash
# ä½¿ç”¨ GitHacker
python3 GitHacker.py http://target.com/.git/

# ä½¿ç”¨ git-dumper
git-dumper http://target.com/.git/ output_dir

# æŸ¥çœ‹å†å²æäº¤
cd output_dir
git log --oneline
git diff HEAD~1
git show <commit_hash>
```

### å¥—è·¯ 2: .svn æºç æ³„éœ²

**ç‰¹å¾**: è®¿é—® `/.svn/entries` æˆ– `/.svn/wc.db` å­˜åœ¨

**è§£æ³•**:
```bash
# ä½¿ç”¨ dvcs-ripper
perl rip-svn.pl -u http://target.com/.svn/

# æˆ–æ‰‹åŠ¨ä¸‹è½½
sqlite3 .svn/wc.db "select local_relpath from nodes"
```

### å¥—è·¯ 3: DS_Store æ³„éœ²

**ç‰¹å¾**: è®¿é—® `/.DS_Store` è¿”å›äºŒè¿›åˆ¶å†…å®¹

**è§£æ³•**:
```bash
# ä¸‹è½½å¹¶è§£æ
curl http://target.com/.DS_Store -o .DS_Store
python3 ds_store_exp.py http://target.com/.DS_Store
```

### å¥—è·¯ 4: å¤‡ä»½æ–‡ä»¶æ³„éœ²

**ç‰¹å¾**: å¸¸è§å¤‡ä»½æ–‡ä»¶åå­˜åœ¨

**è§£æ³•**:
```bash
# å¸¸è§å¤‡ä»½æ–‡ä»¶
www.zip
www.tar.gz
backup.zip
backup.sql
web.rar
1.zip
filename.php.bak
filename.php~
.filename.php.swp
```

### å¥—è·¯ 5: WEB-INF æ³„éœ²

**ç‰¹å¾**: Java Web åº”ç”¨ï¼Œå¯èƒ½æ³„éœ² web.xml

**è§£æ³•**:
```bash
# å°è¯•è®¿é—®
curl http://target.com/WEB-INF/web.xml
curl http://target.com/WEB-INF/classes/xxx.class

# Nginx é…ç½®ä¸å½“å¯èƒ½å¯¼è‡´
# location /WEB-INF/ æœªé…ç½® deny
```

### å¥—è·¯ 6: ç›®å½•éå†

**ç‰¹å¾**: ç›®å½•åˆ—è¡¨åŠŸèƒ½å¼€å¯

**è§£æ³•**:
```bash
# Nginx ç›®å½•éå†
http://target.com/files/

# Apache ç›®å½•éå†
http://target.com/upload/
```

### å¥—è·¯ 7: phpinfo æ³„éœ²

**ç‰¹å¾**: `phpinfo.php` æˆ– `info.php` å­˜åœ¨

**è§£æ³•**:
```bash
curl http://target.com/phpinfo.php
curl http://target.com/info.php
curl http://target.com/php.php
curl http://target.com/i.php

# ä» phpinfo è·å–é‡è¦ä¿¡æ¯
# - PHP ç‰ˆæœ¬
# - ç¦ç”¨å‡½æ•° (disable_functions)
# - é…ç½®è·¯å¾„
# - ä¸´æ—¶ç›®å½•
```

### å¥—è·¯ 8: é”™è¯¯ä¿¡æ¯æ³„éœ²

**ç‰¹å¾**: é”™è¯¯é¡µé¢æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

**è§£æ³•**:
```bash
# è§¦å‘é”™è¯¯
curl "http://target.com/index.php?id='"
curl "http://target.com/index.php?id[]=1"

# åˆ†æé”™è¯¯ä¿¡æ¯
# - ç»å¯¹è·¯å¾„
# - æ•°æ®åº“ä¿¡æ¯
# - æ¡†æ¶ç‰ˆæœ¬
```

## ä¿¡æ¯æœé›†è‡ªåŠ¨åŒ–è„šæœ¬

```python
#!/usr/bin/env python3
"""
Web ä¿¡æ¯æœé›†è‡ªåŠ¨åŒ–è„šæœ¬
"""

import requests
import re
from urllib.parse import urljoin

def recon(target_url):
    """åŸºç¡€ä¿¡æ¯æœé›†"""
    
    results = {
        'headers': {},
        'sensitive_files': [],
        'technologies': [],
        'endpoints': []
    }
    
    # 1. å“åº”å¤´åˆ†æ
    try:
        resp = requests.get(target_url, timeout=10)
        results['headers'] = dict(resp.headers)
        
        # æå–æŠ€æœ¯æ ˆä¿¡æ¯
        if 'Server' in resp.headers:
            results['technologies'].append(resp.headers['Server'])
        if 'X-Powered-By' in resp.headers:
            results['technologies'].append(resp.headers['X-Powered-By'])
            
    except Exception as e:
        print(f"[-] Error: {e}")
    
    # 2. æ•æ„Ÿæ–‡ä»¶æ£€æµ‹
    sensitive_paths = [
        'robots.txt',
        '.git/HEAD',
        '.svn/entries',
        '.DS_Store',
        'web.xml',
        'WEB-INF/web.xml',
        'phpinfo.php',
        'info.php',
        'www.zip',
        'backup.zip',
        'config.php.bak'
    ]
    
    for path in sensitive_paths:
        url = urljoin(target_url, path)
        try:
            resp = requests.get(url, timeout=5)
            if resp.status_code == 200:
                results['sensitive_files'].append({
                    'path': path,
                    'size': len(resp.content),
                    'content_type': resp.headers.get('Content-Type', '')
                })
                print(f"[+] Found: {path}")
        except:
            pass
    
    # 3. æå– JS æ–‡ä»¶
    try:
        resp = requests.get(target_url)
        js_files = re.findall(r'src=["\']([^"\']*\.js)["\']', resp.text)
        for js in js_files:
            full_url = urljoin(target_url, js)
            results['endpoints'].append(full_url)
            print(f"[*] JS: {full_url}")
    except:
        pass
    
    return results

if __name__ == '__main__':
    import sys
    if len(sys.argv) < 2:
        print("Usage: python3 recon.py http://target.com")
        sys.exit(1)
    
    target = sys.argv[1]
    results = recon(target)
    
    print("\n[=== Results ===]")
    print(f"Technologies: {results['technologies']}")
    print(f"Sensitive Files: {len(results['sensitive_files'])}")
    for f in results['sensitive_files']:
        print(f"  - {f['path']}")
```

## å·¥å…·é€ŸæŸ¥

```bash
# åŸºç¡€ä¿¡æ¯
curl -I http://target.com        # å“åº”å¤´
whatweb http://target.com        # æŠ€æœ¯æ ˆè¯†åˆ«

# ç«¯å£æ‰«æ
nmap -sV -sC target.com          # æœåŠ¡è¯†åˆ«
masscan target.com -p1-65535     # å¿«é€Ÿå…¨ç«¯å£

# ç›®å½•æ‰«æ
dirsearch -u http://target.com   # ç›®å½•æ‰«æ
ffuf -u http://target.com/FUZZ   # Fuzz æ‰«æ

# æºç æ³„éœ²
python3 GitHacker.py http://target.com/.git/  # Git æ³„éœ²
perl rip-svn.pl -u http://target.com/.svn/    # SVN æ³„éœ²

# å­åŸŸå
subfinder -d target.com          # å­åŸŸåæšä¸¾

# URL æ”¶é›†
gau target.com                   # å†å² URL
```
